{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IoxqSHxNdVR"
   },
   "source": [
    "# Importing important libraries and loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqyaqueYA3uw",
    "outputId": "e6146bc8-fd8c-495c-9a5a-1d3d8e46485f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.metrics\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow_addons.metrics\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "msg=pd.read_csv(\"ps5_tweets_text.csv\")\n",
    "label=pd.read_csv(\"ps5_tweets_labels_as_numbers.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsLhhNsePJmq"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "HiAkcS-4Nqjg",
    "outputId": "f65f7dc6-d2c2-49f3-c0c0-bc8acb2f4587"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://t.co/UpjxfOgQs8\\r\\r\\n\\r\\r\\nGaisss! Please read this,and please limit yourself to go outside and please,please..always wash your hands,always use the hand sanitizer. \\r\\r\\n\\r\\r\\nAnd please get ready to stock up the food.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at tweets to see what all needs to be done for cleaning \n",
    "msg['Tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8otVW6kA3vI",
    "outputId": "14aecfec-ade9-461d-d9fe-729aabcf0146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    10282\n",
       "1     8930\n",
       "2     6930\n",
       "4     5953\n",
       "0     4946\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counts of all classes to check imbalance\n",
    "label['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIbSP5IAU5wx"
   },
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CxZ_XKNfA3vJ"
   },
   "outputs": [],
   "source": [
    "#joining data to form train and test set\n",
    "full_data=pd.concat([msg,label[['Label']]],axis=1,join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gaxDnYEYA3vM"
   },
   "outputs": [],
   "source": [
    "#splitting data into train,validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split( full_data[['Tweet']], full_data[['Label']], test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeUlIjgRYZU9"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TwRYc6HsA3vQ"
   },
   "outputs": [],
   "source": [
    "#cleaning train set tweets by removing URLs, usernames and '#', and converting all words to lowercase\n",
    "train_data=[]\n",
    "for i in range(len(X_train)):\n",
    "\n",
    "    temp = X_train['Tweet'].iloc[i].lower() # converting text to lower-case\n",
    "    temp = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '',temp) # removing URLs\n",
    "    temp = re.sub('@[^\\s]+', '', temp) # removing usernames\n",
    "    temp = re.sub(r'#([^\\s]+)', '', temp) # removing the # in #hashtag\n",
    "    temp = word_tokenize(temp)        #splitting string into list of tokens\n",
    "    train_data.append(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BhL8zbMpA3vT"
   },
   "outputs": [],
   "source": [
    "#removing stop words from tweets\n",
    "stopwords=stopwords.words('english')+list(punctuation)\n",
    "for i in range(len(train_data)):  \n",
    "    train_data[i] = [word for word in  train_data[i] if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnEnkIwiYpF4"
   },
   "source": [
    "# Calculating vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rdCTBqDTA3vW"
   },
   "outputs": [],
   "source": [
    "#making vocab of all words in training data\n",
    "all_words=[]\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        all_words.append(train_data[i][j])\n",
    "\n",
    "wordlist = nltk.FreqDist(all_words)\n",
    "word_features = wordlist.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBVXKmguA3vZ",
    "outputId": "2b973dac-10be-4e91-fd6b-5d049bea981f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28427"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vocab size\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-avWLxKY0QQ"
   },
   "source": [
    "# Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "U4bmjrMPR6w2"
   },
   "outputs": [],
   "source": [
    "#using tensorflow tokenizer to vectorize words and fitting it to train set to form embedding\n",
    "tokenizer=Tokenizer(num_words=len(word_features))\n",
    "tokenizer.fit_on_texts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MUCsXxr4cnp_"
   },
   "outputs": [],
   "source": [
    "#using tokenizer converting train data to one hot vectors\n",
    "one_hot_res=tokenizer.texts_to_matrix(train_data,mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-DTMZSuc83d",
    "outputId": "85ba1bd8-0f16-47cc-c315-0b359965acfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22224, 28427)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7KxmktbY6KG"
   },
   "source": [
    "# Training models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UQPdr9KY9G9"
   },
   "source": [
    " **Model 1 - Multinomial Naive Bayes classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZP1MFH1c9nP",
    "outputId": "40ec387a-1a16-492c-a35c-5f426586ef68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(one_hot_res, y_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BEuUEiwJgrTY",
    "outputId": "09525e09-cd92-4d57-90e7-53fd57d2c59c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765703743700504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for train set\n",
    "clf.score(one_hot_res,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Gs_rdn6GT6Wg"
   },
   "outputs": [],
   "source": [
    "#applying same transformations to validation and test set\n",
    "val_data=[]\n",
    "for i in range(len(X_val)):\n",
    "\n",
    "    temp = X_val['Tweet'].iloc[i].lower() # converting text to lower-case\n",
    "    temp = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '',temp) # removing URLs\n",
    "    temp = re.sub('@[^\\s]+', '', temp) # removing usernames\n",
    "    temp = re.sub(r'#([^\\s]+)', '', temp) # removing the # in #hashtag\n",
    "    temp = word_tokenize(temp) #splitting string into list of tokens\n",
    "    val_data.append(temp)\n",
    "    \n",
    "test_data=[]\n",
    "for i in range(len(X_test)):\n",
    "\n",
    "    temp = X_test['Tweet'].iloc[i].lower() # converting text to lower-case\n",
    "    temp = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '',temp) # removing URLs\n",
    "    temp = re.sub('@[^\\s]+', '', temp) # removing usernames\n",
    "    temp = re.sub(r'#([^\\s]+)', '', temp) # removing the # in #hashtag\n",
    "    temp = word_tokenize(temp) #splitting string into list of tokens\n",
    "    test_data.append(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Hzm6r3PyUSH6"
   },
   "outputs": [],
   "source": [
    "for i in range(len(val_data)):  \n",
    "    val_data[i] = [word for word in  val_data[i] if word not in stopwords]\n",
    "\n",
    "for i in range(len(test_data)):  \n",
    "    test_data[i] = [word for word in  test_data[i] if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vJqnlyHmUyQW"
   },
   "outputs": [],
   "source": [
    "one_hot_val=tokenizer.texts_to_matrix(val_data,mode='binary')\n",
    "one_hot_test=tokenizer.texts_to_matrix(test_data,mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "TqINGzJ8ju18"
   },
   "outputs": [],
   "source": [
    "#predictions of Multinomial Naive Bayes Classifier models with validation and test set\n",
    "y_pred_val1=clf.predict(one_hot_val)\n",
    "y_pred_test1=clf.predict(one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5Lev7Neky14",
    "outputId": "5827d4ec-7426-4e3f-fac5-d394b89cf943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44377646382609964"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Macro F1 score for validation set\n",
    "f1macro_MNB_val=f1_score(y_val, y_pred_val1, average='macro')\n",
    "f1macro_MNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZTlwWsbVEFk",
    "outputId": "52a0deb2-4541-4871-ca9d-77bf0e45ca30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4619330453563715"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Micro F1 score for validation set\n",
    "f1micro_MNB_val=f1_score(y_val, y_pred_val1, average='micro')\n",
    "f1micro_MNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdg_OXaDVtw9",
    "outputId": "f9e52120-1e88-4d60-e78a-f8dade88fbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4619330453563715"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for validation set\n",
    "acc_MNB_val=clf.score(one_hot_val,y_val)\n",
    "acc_MNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HeOfturTW8Pz",
    "outputId": "d0055128-0b93-4ff8-98b6-d07dd7c19721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44208616742657725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Macro F1 score for test set\n",
    "f1macro_MNB_test=f1_score(y_test, y_pred_test1, average='macro')\n",
    "f1macro_MNB_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HevxDDkmYIqX",
    "outputId": "290d7875-3060-4c55-d03f-cd2b4eb66573"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45836145228775815"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Micro F1 score for test set\n",
    "f1micro_MNB_test=f1_score(y_test, y_pred_test1, average='micro')\n",
    "f1micro_MNB_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRQl7RLCYMXt",
    "outputId": "36b26a68-22ff-45ce-9dfa-bb8ed90220c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45836145228775815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for test set\n",
    "acc_MNB_test=clf.score(one_hot_test,y_test)\n",
    "acc_MNB_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7QQN12mZj8Q"
   },
   "source": [
    "**Model 2 - Complement Naive Bayes Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78-U5T_ues_b",
    "outputId": "4985ba05-5cc7-4aea-ff6b-9c1d65fc6ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = sklearn.naive_bayes.ComplementNB()\n",
    "clf2.fit(one_hot_res, y_train['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhWHU32qe_ks",
    "outputId": "bf71c90c-79c1-499d-a15c-1f9c2a1aeeaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103851691864651"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for train set \n",
    "clf2.score(one_hot_res,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "dtVFBfgaf_b0"
   },
   "outputs": [],
   "source": [
    "#predictions of Complement Naive Bayes Classifier models with validation and test set\n",
    "y_pred_val2=clf2.predict(one_hot_val)\n",
    "y_pred_test2=clf2.predict(one_hot_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzFhvzTyhw4N",
    "outputId": "a55fcb0a-22d8-41d2-e233-4f0e427352a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4532259942099035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Macro F1 score for validation set\n",
    "f1macro_CNB_val=f1_score(y_val, y_pred_val2, average='macro')\n",
    "f1macro_CNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZP-4Y2ehxuU",
    "outputId": "70e43ae8-5ce9-451a-b67b-7f1fec038017"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44681425485961124"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Micro F1 score for validation set\n",
    "f1micro_CNB_val=f1_score(y_val, y_pred_val2, average='micro')\n",
    "f1micro_CNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ezXI7wP8hx4Q",
    "outputId": "b3255cec-ecbd-4a13-df74-97e35fcc007f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4619330453563715"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for validation set\n",
    "acc_CNB_val=clf.score(one_hot_val,y_val)\n",
    "acc_CNB_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwK65MROhx7G",
    "outputId": "0b0d36c7-1539-4dfc-c75d-c44479ecace6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45424342055810707"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Macro F1 score for test set\n",
    "f1macro_CNB_test=f1_score(y_test, y_pred_test2, average='macro')\n",
    "f1macro_CNB_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XB-yrCpxhx-j",
    "outputId": "8f3113d5-f0fc-4290-882a-4325705c7392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44715886084491835"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Micro F1 score for test set\n",
    "f1micro_CNB_test=f1_score(y_test, y_pred_test2, average='micro')\n",
    "f1micro_CNB_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CG6AqL7dhyAb",
    "outputId": "b715ed33-b9a2-4383-a504-6dbe1f91f615"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45836145228775815"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy for test set\n",
    "acc_CNB_test=clf.score(one_hot_test,y_test)\n",
    "acc_CNB_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3i9Y_7RedfvQ"
   },
   "source": [
    "**Model 3 - RNN architecture 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "kGmJiT_HkxqG"
   },
   "outputs": [],
   "source": [
    "#Train test split for RNN, no validation set because cross validation split will be done later\n",
    "X_train, X_test, y_train, y_test = train_test_split( full_data[['Tweet']], full_data[['Label']], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ndFxmXWi48il"
   },
   "outputs": [],
   "source": [
    "#applying same transformations for new train set and test set\n",
    "train_data=[]\n",
    "for i in range(len(X_train)):\n",
    "\n",
    "    temp = X_train['Tweet'].iloc[i].lower() # convert text to lower-case\n",
    "    temp = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '',temp) # remove URLs\n",
    "    temp = re.sub('@[^\\s]+', '', temp) # remove usernames\n",
    "    temp = re.sub(r'#([^\\s]+)', '', temp) # remove the # in #hashtag\n",
    "    temp = word_tokenize(temp)  #splitting string into list of tokens\n",
    "    train_data.append(temp)\n",
    "\n",
    "test_data=[]\n",
    "for i in range(len(X_test)):\n",
    "\n",
    "    temp = X_test['Tweet'].iloc[i].lower() # convert text to lower-case\n",
    "    temp = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', '',temp) # remove URLs\n",
    "    temp = re.sub('@[^\\s]+', '', temp) # remove usernames\n",
    "    temp = re.sub(r'#([^\\s]+)', '', temp) # remove the # in #hashtag\n",
    "    temp = word_tokenize(temp)  #splitting string into list of tokens\n",
    "    test_data.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "4-xSlApS5r1d"
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_data)):  \n",
    "    train_data[i] = [word for word in  train_data[i] if word not in stopwords]\n",
    "\n",
    "for i in range(len(test_data)):  \n",
    "    test_data[i] = [word for word in  test_data[i] if word not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izKBsB6VlAlB"
   },
   "source": [
    "# Calculating vocab again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62llIY7v5HtA",
    "outputId": "62f43348-ef91-4488-f3c4-b02150a13484"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33276"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words=[]\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        all_words.append(train_data[i][j])\n",
    "\n",
    "wordlist = nltk.FreqDist(all_words)\n",
    "word_features = wordlist.keys()\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjXX6z4BlJZB"
   },
   "source": [
    "# Tokenizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "_ne8NybX5Pqo"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=len(word_features))\n",
    "tokenizer.fit_on_texts(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-W85sBWgyGay"
   },
   "outputs": [],
   "source": [
    "#converting train and test data to sequence of numbers\n",
    "train_data_final=tokenizer.texts_to_sequences(train_data)\n",
    "test_data_final=tokenizer.texts_to_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT5uc1L4lV2S"
   },
   "source": [
    "# Padding train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4SeVn681ysr3"
   },
   "outputs": [],
   "source": [
    "#making length of train and test data instances uniform by padding with zeros\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(train_data_final, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(test_data_final, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "YPRb0a387qmv"
   },
   "outputs": [],
   "source": [
    "#converting target labels into one hot vectors\n",
    "y_train_one_hot=tf.one_hot(y_train['Label'],5)\n",
    "y_test_one_hot=tf.one_hot(y_test['Label'],5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0s4wEr6ql9lK"
   },
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "b0rLkWigph04"
   },
   "outputs": [],
   "source": [
    "#Trying the RNN architecture with one LSTM layer and one Dense layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(word_features),\n",
    "        output_dim=250,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(5,activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "lywv6b1QvmcF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy',tensorflow_addons.metrics.F1Score(num_classes=5,average='macro',name='F1_macro'),\n",
    "              tensorflow_addons.metrics.F1Score(num_classes=5,average='micro',name='F1_micro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK-DzkBxvqyC",
    "outputId": "568d5fc4-30cb-42ef-8aac-4caf6521de8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "741/741 [==============================] - 121s 146ms/step - loss: 1.5371 - accuracy: 0.2968 - F1_macro: 0.2035 - F1_micro: 0.2968 - val_loss: 1.1484 - val_accuracy: 0.5311 - val_F1_macro: 0.5382 - val_F1_micro: 0.5311\n",
      "Epoch 2/4\n",
      "741/741 [==============================] - 102s 137ms/step - loss: 0.9706 - accuracy: 0.6307 - F1_macro: 0.6356 - F1_micro: 0.6307 - val_loss: 0.9341 - val_accuracy: 0.6256 - val_F1_macro: 0.6342 - val_F1_micro: 0.6256\n",
      "Epoch 3/4\n",
      "741/741 [==============================] - 104s 140ms/step - loss: 0.6233 - accuracy: 0.7955 - F1_macro: 0.8010 - F1_micro: 0.7955 - val_loss: 0.8933 - val_accuracy: 0.6680 - val_F1_macro: 0.6746 - val_F1_micro: 0.6680\n",
      "Epoch 4/4\n",
      "741/741 [==============================] - 104s 140ms/step - loss: 0.4187 - accuracy: 0.8733 - F1_macro: 0.8762 - F1_micro: 0.8733 - val_loss: 0.9679 - val_accuracy: 0.6676 - val_F1_macro: 0.6765 - val_F1_micro: 0.6676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27987f89ec8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_one_hot,epochs=4,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WExa7KrWmhG3"
   },
   "source": [
    "# Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7UmJ2ebwAKn",
    "outputId": "f139eaf2-5b46-443a-d52d-0e09d471e9dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 4s 16ms/step - loss: 0.9963 - accuracy: 0.6749 - F1_macro: 0.6814 - F1_micro: 0.6749\n"
     ]
    }
   ],
   "source": [
    "model1_loss,model1_acc,model1_f1macro,model1_f1micro=model.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "A8XjaeDzAXfD"
   },
   "outputs": [],
   "source": [
    "#predicting labels for test set \n",
    "y_test_pred=np.argmax(model.predict(X_test),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHyZS78AAdyG",
    "outputId": "0569dbfb-431e-4e5a-ec57-feed6d15890a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, ..., 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWSMV9ce_3OZ",
    "outputId": "e9121331-759a-45eb-a02f-c7d58ac39264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[ 580,  340,   24,   26,    5],\n",
       "       [ 145, 1123,  230,  262,   10],\n",
       "       [   3,  152, 1060,  212,    5],\n",
       "       [  15,  253,  162, 1463,  136],\n",
       "       [   3,   24,    8,  394,  774]])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "tf.math.confusion_matrix(y_test['Label'], y_test_pred, num_classes=5, weights=None, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RAdzsTwm8TR"
   },
   "source": [
    "**Model 2 - RNN architecture 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me0HIahqnMq9"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "32wqzF8lAdKd"
   },
   "outputs": [],
   "source": [
    "#Second RNN model with two LSTM layers and a dropout layer\n",
    "model2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(word_features),\n",
    "        output_dim=250,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100,return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(5,activation='softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "A6kRzDafkRE4"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy',tensorflow_addons.metrics.F1Score(num_classes=5,average='macro',name='F1_macro'),\n",
    "              tensorflow_addons.metrics.F1Score(num_classes=5,average='micro',name='F1_micro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6LENnXvSk56R",
    "outputId": "ad8856d8-abdb-41ec-c43a-0cf22f3eb401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "741/741 [==============================] - 192s 230ms/step - loss: 1.5291 - accuracy: 0.2997 - F1_macro: 0.2066 - F1_micro: 0.2997 - val_loss: 1.1169 - val_accuracy: 0.5769 - val_F1_macro: 0.5780 - val_F1_micro: 0.5769\n",
      "Epoch 2/3\n",
      "741/741 [==============================] - 208s 281ms/step - loss: 0.9741 - accuracy: 0.6381 - F1_macro: 0.6436 - F1_micro: 0.6381 - val_loss: 0.9059 - val_accuracy: 0.6599 - val_F1_macro: 0.6664 - val_F1_micro: 0.6599\n",
      "Epoch 3/3\n",
      "741/741 [==============================] - 180s 243ms/step - loss: 0.6397 - accuracy: 0.7947 - F1_macro: 0.7993 - F1_micro: 0.7947 - val_loss: 0.8854 - val_accuracy: 0.6789 - val_F1_macro: 0.6841 - val_F1_micro: 0.6789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x279893abc48>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train_one_hot,epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZpTrihgnQxM"
   },
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBOJWrEVk962",
    "outputId": "c2f3ee86-516d-4dcc-b4b6-e9c6e02e875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/232 [==============================] - 6s 28ms/step - loss: 0.8972 - accuracy: 0.6825 - F1_macro: 0.6871 - F1_micro: 0.6825\n"
     ]
    }
   ],
   "source": [
    "model2_loss,model2_acc,model2_f1macro,model2_f1micro=model2.evaluate(X_test,y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "PSBUf_n6ohGn",
    "outputId": "57ad05d2-4f34-40db-ffc8-0269d5ee8ad6"
   },
   "outputs": [],
   "source": [
    "#predicting labels for test set \n",
    "y_test_pred2=np.argmax(model2.predict(X_test),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "-5iX2ExHoqDC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=int32, numpy=\n",
       "array([[ 535,  398,   12,   26,    4],\n",
       "       [  92, 1209,  234,  229,    6],\n",
       "       [   1,  179, 1079,  171,    2],\n",
       "       [  13,  213,  243, 1449,  111],\n",
       "       [   2,   22,   12,  382,  785]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "tf.math.confusion_matrix(y_test['Label'], y_test_pred2, num_classes=5, weights=None, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxSw6qB-neJ7"
   },
   "source": [
    "# Comparing models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "NXysBadwngPm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <th>Complement Naive Bayes</th>\n",
       "      <th>RNN model 1</th>\n",
       "      <th>RNN model 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.458361</td>\n",
       "      <td>0.458361</td>\n",
       "      <td>0.674855</td>\n",
       "      <td>0.682548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_macro</th>\n",
       "      <td>0.442086</td>\n",
       "      <td>0.454243</td>\n",
       "      <td>0.681447</td>\n",
       "      <td>0.687096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_micro</th>\n",
       "      <td>0.458361</td>\n",
       "      <td>0.447159</td>\n",
       "      <td>0.674855</td>\n",
       "      <td>0.682548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Multinomial Naive Bayes  Complement Naive Bayes  RNN model 1  \\\n",
       "Accuracy                 0.458361                0.458361     0.674855   \n",
       "F1_macro                 0.442086                0.454243     0.681447   \n",
       "F1_micro                 0.458361                0.447159     0.674855   \n",
       "\n",
       "          RNN model 2  \n",
       "Accuracy     0.682548  \n",
       "F1_macro     0.687096  \n",
       "F1_micro     0.682548  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=['Accuracy','F1_macro','F1_micro']\n",
    "index=['Multinomial Naive Bayes','Complement Naive Bayes','RNN model 1','RNN model 2']\n",
    "acc=[acc_MNB_test,acc_CNB_test,model1_acc,model2_acc]\n",
    "f1macro=[f1macro_MNB_test,f1macro_CNB_test,model1_f1macro,model2_f1macro]\n",
    "f1micro=[f1micro_MNB_test,f1micro_CNB_test,model1_f1micro,model2_f1micro]\n",
    "df=pd.DataFrame([acc,f1macro,f1micro],columns=index,index=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Mahak_Agarwal_PS5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
